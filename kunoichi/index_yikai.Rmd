---
title: "End-to-end data analysis pipeline"
subtitle: 'An visualization journey'
author: "<br>Yikai Zhao&nbsp;&nbsp;&nbsp;`r anicon::faa('twitter', animate='vertical', rtext='&nbsp;@zhao_yikai')`"
institute: "Looking for a full time position as Data scientist"
date: "25-Oct-2019 &nbsp;&nbsp; `r anicon::faa('link', animate='ring', rtext='&nbsp;ykzhao.com', color='white')`"
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: ["assets/shinobi.css", "assets/ninjutsu.css", "assets/ninpo.css", "assets/default.css"]
    nature:
      ratio: "16:9"
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
editor_options: 
  chunk_output_type: console
---

class: center, middle

<img src="images/data_scientist.png" width="25%">


```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(dpi = 300,  out.width = "80%", message = F, warning = F) # this is set for the aesthetics of the 
# flipplot remember to add out.width to all other plots


```



---


class: split-60 white 

.column.bg-main1[.content.vmiddle[
# Overview
<br>
### Data visualization is important to

* #### draw insights amid the data analysis
* #### convey those insights to customers & decision makers


### This powerpoint aims to use .orange[visualizations] to showcase the process of data analysis from data cleaning to final model interpretation

### I will use the House Prices dataset from [Kaggle](https://www.kaggle.com/c/house-prices-advanced-regression-techniques)


### The information about this dataset could be glanced from right


]]



.column.bg-main4[.content.vmiddle.center[
<center>
```{r echo = FALSE, message=FALSE, warning=FALSE }
library(knitr)
library(ggplot2)
library(plyr)
library(dplyr)
library(reshape2)
library(corrplot)
# library(caret)
# library(gridExtra)
# library(scales)
# library(Rmisc)
library(ggrepel)
library(plotly)
# library(randomForest)
# library(psych)
# library(xgboost)
train <- read.csv("../kunoichi/data/train_house.csv", stringsAsFactors = F)
test <- read.csv("../kunoichi/data/test_house.csv", stringsAsFactors = F)
test_labels <- test$Id
test$Id <- NULL
train$Id <- NULL
test$SalePrice <- NA
all <- rbind(train, test)
```

```{r, eval = F}
# The dimention of the data are
dim(train)
dim(test)
```

```{r, eval=F}
[1] 1460   80
[1] 1459   80
```

### There are 79 predictors and we will use them to predict our response variable .teal[SalePrice] of houses. 
]]

---
class: bg-main1 center middle hide-slide-number

.reveal-text[.pad1[
.font4[There will be three major parts
]
]]


---
layout: true

class: split-three 

.column.bg-main1[.content[
#  Data exploration and manipulation 
### This step involves dealing of .orange[missing data] and .teal[outliers]:
  + ### missing at random or missing with pattern(s)
  + ### impute or discard them
  
### View the distribution of variables and their relaitonships
### Deal with skewed variables
### Feature engineering 

]]
.column.bg-main1[.content[
# Predicative modeling

## Choose the appropriate modeling architecture(s)
## .orange[hyperparamerter tuning] 
## .teal[ensembling] the models for better generalibility
]]
.column.bg-main1[.content[
# Results interpretation

## Interpretable machine learning
## .orange[Shapley] values to attribute contributions to variables
## View interactions between variables
]]

---

class: gray-col2 gray-col3
count: false

---

class: gray-col3
count: false

---

count: false

---
layout: false

class: bg-main1, center, middle

# Part 1: Data exploration and manipulation

---

layout: false
class: split-50 
.column.bg-main1[.content.vmiddle[

# Which numerical variables are important to explore first

## We could find variables with a correlation of at least 0.5 with our dependent variable .orange[SalePrice]

]]

.column.bg-main5[.content.vmiddle.center[

```{r, echo= F, out.width= '100%', warning=F, message= F}
numericVars <- which(sapply(all, is.numeric)) #index vector numeric variables
numericVarNames <- names(numericVars) #saving names vector for use later on

all_numVar <- all[, numericVars]
cor_numVar <- cor(all_numVar, use="pairwise.complete.obs") #correlations of all numeric variables

#sort on decreasing correlations with SalePrice
cor_sorted <- as.matrix(sort(cor_numVar[,'SalePrice'], decreasing = TRUE))
 #select only high corelations
CorHigh <- names(which(apply(cor_sorted, 1, function(x) abs(x)>0.5)))
cor_numVar <- cor_numVar[CorHigh, CorHigh]
```

```{r, out.height= "40%" }
#sorted on decreasing correlations with SalePrice
corrplot.mixed(cor_numVar, tl.col="black", tl.pos = "lt")
```


]]


---

class: split-50

.column.bg-main1[.content.vmiddle.center[
# We could visualize the relationship between .tile[GrLivArea] and .orange[SalePrice]
From the plot, the 524th and 1299th house are potential outliers that deserve special attention. We furter insepct the OverallQual of these two hourse

```{r, echo = T}
knitr::kable(all[c(524, 1299), c('SalePrice', 'GrLivArea', 'OverallQual', "Neighborhood")]
, format = "html")
```

These two houses are all of the highest quality however located at a "normal" .tile[neighborhood], which might explain the low price. Thus we keep these two houses in the dataset. 


]]

.column.bg-main5[.content.vmiddle.center[


```{r, out.width = "80%", echo = F}
p = ggplot(data=all[!is.na(all$SalePrice),], aes(x=GrLivArea, y=SalePrice))+
        geom_point(color = ifelse(all$GrLivArea[!is.na(all$SalePrice)]>4500, "red", "grey50")) + 
        geom_smooth(method = "lm", se=FALSE, color="black", lty = "dotted") +
        scale_y_continuous(breaks= seq(0, 800000, by=100000), labels = scales::comma) +
        geom_text_repel(aes(label = ifelse(all$GrLivArea[!is.na(all$SalePrice)]>4500, rownames(all), '')))+
        theme_bw()+
        theme(plot.subtitle = element_text(color = 'grey70'))+
        theme(panel.border = element_blank())+
        theme(plot.title = element_text(lineheight = .8, face = "bold", size = 16))+
        theme(panel.grid.minor = element_blank())+
        theme(plot.subtitle = element_text(color = 'darkgray'))+
        theme(axis.line.x = element_line(color = 'darkgrey', size = 0.5))+
        labs(title = "Relationship between SalesPrice and GrLivArea")+
        labs(subtitle = "Data Source: House Prices Competition in Kaggle")+
        labs(caption = "Vis: @zhao_yikai with ggplot")
p
```


]]
---
class: bg-main1, center, middle


###  In the next slide, we visualize the relationship between .yellow[OverallQual] and .orange[SalePrice] in steps.

# We could customize the visualization with great flexibility to the businuess needs. 

---
```{r, echo = FALSE, warning = F, message= F}

training_data = all[!is.na(all$SalePrice), ]

lb <- function(x) mean(x) - sd(x)
ub <- function(x) {

  return(mean(x) + sd(x))
}

source("https://gist.githubusercontent.com/benmarwick/2a1bb0133ff568cbe28d/raw/fb53bd97121f7f9ce947837ef1a4c65a73bffb3f/geom_flat_violin.R")


getPalette = colorRampPalette(RColorBrewer::brewer.pal(8, "RdBu"))(10)

sumld <- training_data %>% 
  dplyr::select(OverallQual, SalePrice) %>% 
  group_by(OverallQual) %>% 
  summarise_all(funs(mean, median, lower = lb, upper = ub))

source("https://raw.githubusercontent.com/EvaMaeRey/little_flipbooks_library/master/xaringan_reveal_parentheses_balanced.R")

```

```{r rainplot, eval = F, echo = F,  out.width = "100%", warning = F, message = F, dpi= 300}
# We could visualize the distribution
# of variable OverallQual in a rainplot
ggplot(data = training_data, 
  aes(x = factor(OverallQual), y = SalePrice, fill=factor(OverallQual))) +
  geom_flat_violin(position = position_nudge(x = .2, y = 0), trim = TRUE, alpha = .8, scale = "width") +
  geom_point(aes(y = SalePrice, color = factor(OverallQual)), 
             position = position_jitter(width = .15), size = .5, alpha = 1) +
  geom_boxplot(width = .1, outlier.shape = NA, alpha = 0.5) +
  geom_point(data = sumld, aes(x = factor(OverallQual), y = mean), 
             position = position_nudge(x = 0.3), size = 2.5) +
  geom_errorbar(data = sumld, aes(ymin = lower, ymax = upper, y = mean), 
                position = position_nudge(x = 0.3), width = 0)+
  expand_limits(x = 5.25) +
  guides(fill = FALSE, color = F) +
  scale_color_manual(values = getPalette) +
  scale_fill_manual(values = getPalette) +
  coord_trans(y = 'log2') +
  labs( y = 'SalePrice', x = 'OverallQual' ) +
  annotate("text", x = 4, y = 3e+05, label = c('outlier?'))+
  labs(title = "Relationship between SalesPrice and OverallQual")+
  labs(subtitle = "Data Source: House Prices Competition in Kaggle", 
       caption = "Vis: @zhao_yikai with ggplot")+
  theme_bw()+
  theme(plot.subtitle = element_text(color = 'grey50'))+
  theme(panel.border = element_blank())+
  theme(plot.title = element_text(lineheight = .8, face = "bold", size = 16))+
  theme(panel.grid.minor = element_blank())+
  theme(axis.line.x = element_line(color = 'darkgrey', size = 0.5))+
  scale_y_continuous(breaks= seq(0, 800000, by=100000), labels =scales::comma)
  
```


`r apply_reveal("rainplot")`



---
class: split-60  

.column.bg-main1[.content.vmiddle[

# Plotting the missingness in that dataset 

###.orange[white lines] indicate missing values in the corresponding variable
### some variables have missingness at random, some have huge missingness
### Turns out some missingness indicate the .orange[absence] of that feature (e.g. a pool or fense)
### some are data misentry and we need to .yellow[find them out!] 


]]

.column.bg-main5[.content.vmiddle.center[
<center>

```{r, echo = F}
  all[, 1:ncol(all)] %>%
    is.na %>%
    melt %>%
    group_by(Var2) %>%
    summarise(n_missing = sum(value)) -> missing_cols
```

```{r plot_themes, echo=F, message=F, warning=F}
yikai_labels <- list(
   labs(subtitle = "Data Source: House Prices Competition in Kaggle"),
   labs(caption = "Vis: @zhao_yikai with ggplot")
             )

yikai_themes = theme(
  plot.subtitle = element_text(color = 'grey30'),
  panel.border = element_blank(),
  plot.title = element_text(lineheight = .8, face = "bold", size = 16),
  panel.grid.minor = element_blank(),
  axis.line.x = element_line(color = 'darkgrey', size = 0.5),
  plot.title.position = "plot", 
  plot.caption.position =  "plot") #NEW parameter
```


```{r, message= F, warning=F, echo = F, out.width = "90%" , dpi = 300, out.height= "75%"}
  all[, 1:ncol(all)] %>%
    is.na %>%
    melt %>%
    filter(Var2 %in% missing_cols$Var2[missing_cols$n_missing > 0]) %>%
  ggplot(data = .,
         aes(x = Var2,
             y = Var1)) +
    geom_raster(aes(fill = value)) +
    scale_fill_grey(name = "",
                    labels = c("Present","Missing")) +
    theme_minimal() +
    theme(axis.text.x  = element_text(angle=90, vjust=0.5)) +
    labs(x = "Variables in Dataset",
         y = "Rows / observations")+
    yikai_themes+
    yikai_labels+
    theme(panel.grid.minor = element_blank())+
    theme(panel.grid.major = element_blank())


  
```


]]

---








---
