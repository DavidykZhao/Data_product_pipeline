



class: split-50

.column.bg-main1[.content.vmiddle[

# To achieve great .orange[predicability] and .orange[explanabiity]
# XGBoost model is used
# A Bayesian hyperparameter tuning was conducted to find the optimal combination of hyperparamters from our XGBoost model


]]

.column.bg-main5[.content.vmiddle.center[


```{r, echo = F}
train1 = readRDS("data/training_x.rds")
train_y_include = readRDS("data/training_y_included.rds")

label_train <- train_y_include["SalePrice"]

# put our testing & training data into two seperates Dmatrixs objects
dtrain <- xgb.DMatrix(data = as.matrix(train1), label= as.matrix(label_train))
#dtest <- xgb.DMatrix(data = as.matrix(test1))

default_param <-list(
        objective = "reg:linear",
        booster = "gbtree",
        eta= 0.114, #default = 0.3
        gamma=0.009,
        max_depth=3, #default=6
        min_child_weight=4, #default=1
        subsample=0.975,
        colsample_bytree=0.503,
        colsample_bylevel = 0.564,
        lambda = 2.631,
        alpha = 0.004
)

xgb_mod <- xgb.train(data = dtrain, params=default_param, nrounds = 178)

library(Ckmeans.1d.dp) #required for ggplot clustering
mat <- xgb.importance (feature_names = colnames(train1),model = xgb_mod)
xgb.ggplot.importance(importance_matrix = mat[1:20], rel_to_first = TRUE)

```



]]



---

class: split-50


.column.bg-main1[.content.vmiddle[

# We could view feature importance through SHAPLEY values.
## SHAP utilizes SHAPLEY values to attribute contributions to features
### For more about SHAP or SHAPLEY values, please look at [here](https://github.com/slundberg/shap):


]]

.column.bg-main5[.content.vmiddle.center[



```{r, echo = F, warning= F, message = F}
# to make SHAP summary plot
library('SHAPforxgboost')

mod <- xgboost::xgboost(data = as.matrix(train1), label = as.matrix(label_train), 
                       xgb_param = default_param, nrounds = 301,
                       verbose = FALSE, nthread = parallel::detectCores() - 2,
                       early_stopping_rounds = 8)
#shap_values <- shap.values(xgb_model = mod, X_train = train1)

shap_long <- shap.prep(xgb_model = mod, X_train = train1)
# find out the top20 names
top20_names = shap_long %>%
  select(variable, mean_value) %>%
  arrange(desc(mean_value)) %>%
  unique() %>%
  top_n(20)

top20_names$variable = droplevels(top20_names$variable)
top_20_feature_field = 
  train1 %>%
  select(as.character(top20_names$variable))

shap_top20 = shap_long %>%
  filter(variable %in% top20_names$variable)
shap_top20$variable = droplevels(shap_top20$variable)

shap.plot.summary(shap_top20) + yikai_labels + yikai_themes




```

]]

---










