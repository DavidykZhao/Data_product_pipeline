---
title: "Data analysis pipeline"
subtitle: 'An visualization journey'
author: "<br>Yikai Zhao&nbsp;&nbsp;&nbsp; [`r anicon::faa('twitter', animate='vertical', rtext='&nbsp;@zhao_yikai', color='white')`](https://twitter.com/zhao_yikai)"
institute: "Looking for a full time position as a UX researcher or Data scientist"
date: "25-Oct-2019 &nbsp;&nbsp; [`r anicon::faa('link', animate='ring', rtext='&nbsp;ykzhao.com', color='white')`](ykzhao.com)"
output:
  xaringan::moon_reader:
    chakra: libs/remark-latest.min.js
    lib_dir: libs
    css: ["assets/shinobi.css", "assets/ninjutsu.css", "assets/ninpo.css", "assets/default.css"]
    nature:
      ratio: "16:9"
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
editor_options: 
  chunk_output_type: console
---

```{r child='gif_page.Rmd', warning=F, message=F}
```


---


class: split-60 white 

.column.bg-main1[.content.vmiddle[
# Overview
<br>

## This powerpoint aims to use .orange[visualizations] to showcase the process of data analysis

### Specific details within the process are stripped if there is no good way for visualization such as missing value imputation and model training

### I will use the House Prices dataset from [Kaggle](https://www.kaggle.com/c/house-prices-advanced-regression-techniques)




]]



.column.bg-main4[.content.vmiddle.center[
<center>


```{r setup, include=FALSE, warning= F, message= F}

options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(dpi = 300,  out.width = "80%", message = F, warning = F) # this is set for the aesthetics of the 
# flipplot remember to add out.width to all other plots
source("https://raw.githubusercontent.com/EvaMaeRey/little_flipbooks_library/master/xaringan_reveal_parentheses_balanced.R")
source(file = "~/Data_product_pipeline/docs/xaringan_reveal_parenthetical.R")
library(magick)
logo <- image_read("./images/TAMU_logo.png")

```



```{r echo = FALSE, message=FALSE, warning=FALSE }
library(knitr)
library(ggplot2)
library(plyr)
library(dplyr)
library(reshape2)
library(corrplot)
# library(caret)
# library(gridExtra)
# library(scales)
# library(Rmisc)
library(ggrepel)
library(plotly)
library(randomForest)
library(magick)

# library(psych)
# library(xgboost)
train <- read.csv("~/Data_product_pipeline/docs/data/train_house.csv", stringsAsFactors = F)
test <- read.csv("~/Data_product_pipeline/docs/data/test_house.csv", stringsAsFactors = F)
test_labels <- test$Id
test$Id <- NULL
train$Id <- NULL
test$SalePrice <- NA
all <- rbind(train, test)


```

```{r plot_themes, echo=F, message=F, warning=F}

yikai_labels <- list(
   labs(subtitle = "Data Source: House Prices Competition in Kaggle"),
   labs(caption = "Vis: @zhao_yikai with ggplot")
             )

yikai_palette  <- c("#FFDB6D", "#C4961A", "#F4EDCA", 
                "#D16103", "#C3D7A4", "#52854C", "#4E84C4", "#293352")
yikai_themes = theme(
  plot.subtitle = element_text(color = 'grey50'),
  panel.border = element_blank(),
  plot.title = element_text(face = "bold", size = 16),
  panel.grid.minor = element_blank(),
  axis.line.x = element_line(color = 'darkgrey', size = 0.5),
  plot.title.position = "panel", 
  plot.caption.position =  "plot") #NEW parameter


logo <- image_read("./images/TAMU_logo.png")

```

### The information about this dataset:


```{r, eval = F}
# The dimention of the data are
dim(train)
dim(test)
```


```{r, eval=F}
[1] 1460   80
[1] 1459   80
```

### There are 79 predictors and we will use them to predict our response variable .teal[SalePrice] of houses. 
]]

---
class: bg-main1 center middle hide-slide-number

.reveal-text[.pad1[
.font4[ There will be two major parts
]
]]


---
layout: true

class: split-two 

.row.bg-main1[.content.vmiddle[
#  Data exploration and manipulation 
### This step involves visualizing the relationship between .orange[variables], .teal[missing values] and .pink[possible extreme values]  



]]
.row.bg-main1[.content.vmiddle[
#  Modeling and Model interpretation

### This step involves fitting different models and interpret the .orange[feature importance]


]]


---

class: fade-row2
count: false

---

count: false


---
layout: false

class: bg-main1, center, middle

# Part 1: Data exploration and manipulation

---

layout: false
class: split-50 
.column.bg-main1[.content.vmiddle[

# Which .blue[numerical] variables are important to explore first

## We could find variables with a correlation of at least 0.5 with our dependent variable .deep-orange[SalePrice]

]]

.column.bg-main5[.content.vmiddle.center[

```{r, echo= F, out.width= '100%', warning=F, message= F}
numericVars <- which(sapply(all, is.numeric)) #index vector numeric variables
numericVarNames <- names(numericVars) #saving names vector for use later on

all_numVar <- all[, numericVars]
cor_numVar <- cor(all_numVar, use="pairwise.complete.obs") #correlations of all numeric variables

#sort on decreasing correlations with SalePrice
cor_sorted <- as.matrix(sort(cor_numVar[,'SalePrice'], decreasing = TRUE))
 #select only high corelations
CorHigh <- names(which(apply(cor_sorted, 1, function(x) abs(x)>0.5)))
cor_numVar <- cor_numVar[CorHigh, CorHigh]
```

```{r, out.height= "50%", echo = F}
#sorted on decreasing correlations with SalePrice
corrplot.mixed(cor_numVar, tl.col="black", tl.pos = "lt")
```


]]


---

class: split-50

.column.bg-main1[.content.vmiddle[
# We could visualize the relationship between .pink[GrLivArea] and .orange[SalePrice]



]]

.column.bg-main5[.content.vmiddle.center[


```{r, out.width = "85%", echo = F}
p = ggplot(data=all[!is.na(all$SalePrice),], aes(x=GrLivArea, y=SalePrice))+
        geom_point(color = ifelse(all$GrLivArea[!is.na(all$SalePrice)]>4500, "#E91E63", "grey50"), size = ifelse(all$GrLivArea[!is.na(all$SalePrice)]>4500, 4, 2)) + 
        geom_smooth(method = "lm", se=FALSE, color="black", lty = "dotted") +
        scale_y_continuous(breaks= seq(0, 800000, by=100000), labels = scales::comma) +
        geom_label_repel(aes(label = ifelse(all$GrLivArea[!is.na(all$SalePrice)]>4500, rownames(all), '')))+
        theme_bw()+
        theme(plot.subtitle = element_text(color = 'grey70'))+
        theme(panel.border = element_blank())+
        theme(plot.title = element_text(lineheight = .8, face = "bold", size = 16))+
        theme(panel.grid.minor = element_blank())+
        theme(plot.subtitle = element_text(color = 'darkgray'))+
        theme(axis.line.x = element_line(color = 'darkgrey', size = 0.5))+
        labs(title = "Relationship between SalesPrice and GrLivArea")+
        labs(subtitle = "Data Source: House Prices Competition in Kaggle")+
        labs(caption = "Vis: @zhao_yikai with ggplot")
p
grid::grid.raster(logo, x = 0.79, y = 0.90, just = c('left', 'bottom'), width = unit(1.5, 'inches'))
```


]]

---
class: bg-main1, center, middle


###  In the next slide, we visualize the relationship between .orange[OverallQual] and .deep-orange[SalePrice] in steps.

# We could customize the visualization with great .orange[flexibility] to the businuess needs. 

---

```{r child='flip_plot_seperate_script.Rmd', warning=F, message=F, cache= T}
```


---

class: split-50  

.column.bg-main1[.content.vmiddle[

# Visualize the relationship between .orange[Year] and .teal[SalePrice] by .pink[OverallQual]

The dotted line is roughly the time when the economic crisis happend at the end of 2017.
We could see clearly that the high quality (10) houses get influenced the most.


]]


.column.bg-main5[.content.vmiddle.center[
```{r, echo = F}
all %>%
  select(YrSold, OverallQual, SalePrice) %>%
  filter(!is.na(SalePrice)) %>%
  group_by(YrSold, OverallQual) %>%
  summarise(median_price = median(SalePrice), mean_price = mean(SalePrice)) -> year_by_quality_data

n_qual = paste("N = ", table(all$OverallQual))
x_location = rep(2009, 10)
y_location = c(rep(500000, 9), 200000)
anno_data = data.frame(n_qual = n_qual,
                       YrSold = x_location,
                       median_price = y_location,
                       OverallQual = c(1:10))
```



```{r, echo = F, out.width= "85%", cache = T}
ggplot(data = year_by_quality_data, aes(x = YrSold, y = median_price))+
  geom_line(aes(color = "Median"))+
  facet_wrap(~ OverallQual)+
  geom_line(data = year_by_quality_data, aes(x = YrSold, y = mean_price, color = "Mean"), )+
  scale_y_continuous(breaks = seq(0, 750000, by= 100000), 
                     labels = scales::comma)+
  geom_text(data = anno_data, aes(label = n_qual,
                                  group = NULL))+
  geom_vline(xintercept = 2007.8, linetype = "dotted") +
  theme_light()+
  yikai_labels+
  yikai_themes+
  scale_x_continuous(breaks = c(2007, 2008, 2009), labels = c("07", "08", "09"))+
  scale_y_continuous(breaks = c(100000, 200000, 400000, 600000), labels = c("100k", "200k", "400k", "600k"))+
  theme(panel.grid.major.x = element_blank())+
  theme(legend.position = c(0.8,0.1), legend.direction = "horizontal")+
  theme(legend.background = element_rect(color = "grey" ))+
  theme(panel.spacing.y =
          unit(1, "lines"))+
  labs(y = 'Mean and Median of SalePrice')+
  labs(x = 'Year')+
  labs(title = 'Change of price by Year by OverallQual')
grid::grid.raster(logo, x = 0.79, y = 0.91, just = c('left', 'bottom'), width = unit(1.5, 'inches'))
```



]]


---
```{r child='parallel_plot.Rmd', warning=F, message=F}
```


---

```{r child='PCA_plot.Rmd', warning=F, message=F}
```


---

class: bg-main1, center, middle

# Which .orange[categorical variables] are important to explore

## We could find them via .orange[Random Forest] feature importance.

---

```{r child='lollipop_plot.Rmd', warning=F, message=F, cache= T}
```

---

class: split-50  

.column.bg-main1[.content.vmiddle[
# We could view the .pink[Neighborhood] variable in terms of the median .cyan[SalePrice]


]]

.column.bg-main5[.content.vmiddle.center[

```{r, out.width= "85%", echo = F}

data_circular = readRDS("~/Data_product_pipeline/docs/data/data_circular.RDS")

data_label_circular = data_circular
number_of_bar <- nrow(data_label_circular)
angle <-  90 - 360 * (as.numeric(data_label_circular$Neighborhood, 
                                         data_label_circular$median )-0.5) /number_of_bar
data_label_circular$hjust<-ifelse( angle < -90, 1.2, -0.2)

# flip angle BY to make them readable
data_label_circular$angle<-ifelse(angle < -90, angle+180, angle)
# Make the circular plot


ggplot(data_circular, aes(x= Neighborhood, y=median, fill = as.factor(data_label_circular$NeighRich))) +       # Note that id is a factor. If x is numeric, there is some space between the first bar
  # This add the bars with a blue color
  geom_bar( stat= 'identity') +
  
  # Limits of the plot = very important. The negative value controls the size of the inner circle, the positive one is useful to add size over each bar
  ylim(-400000, 320000) +
  
  # Custom the theme: no axis title and no cartesian grid
  theme_minimal() +
  theme(
    axis.text = element_blank(),
    axis.title = element_blank(),
    panel.grid = element_blank() ) +
  # This makes the coordinate polar instead of cartesian.
  coord_polar(start = 0)+
  geom_text(data=data_label_circular, aes(x=Neighborhood, y=median, label=Neighborhood, hjust=hjust), 
            color="black", fontface="bold",alpha=0.6, 
            size=2.5, angle= data_label_circular$angle, 
            inherit.aes = FALSE ) +
  yikai_themes+
  yikai_labels+
  labs(title = "Median house price by neighborhood")+
  scale_fill_manual(values = c("#E7B800", "#00AFBB", "#FC4E07"))+
  theme(legend.position = "none")

grid::grid.raster(logo, x = 0.79, y = 0.91, just = c('left', 'bottom'), width = unit(1.5, 'inches'))
```



]]

---


```{r child='radar_plot.Rmd', warning=F, message=F}
```




---
class: split-50  

.column.bg-main1[.content.vmiddle[

# Plotting the missing values in the dataset 




]]

.column.bg-main5[.content.vmiddle.center[
<center>

```{r, echo = F}
  all[, 1:ncol(all)] %>%
    is.na %>%
    melt %>%
    group_by(Var2) %>%
    summarise(n_missing = sum(value)) -> missing_cols
```




```{r, message= F, warning=F, echo = F, out.width = "90%" , dpi = 300, out.height= "75%", cache= T}
  all[, 1:ncol(all)] %>%
    is.na %>%
    melt %>%
    filter(Var2 %in% missing_cols$Var2[missing_cols$n_missing > 0]) %>%
  ggplot(data = .,
         aes(x = Var2,
             y = Var1)) +
    geom_raster(aes(fill = value)) +
    scale_fill_grey(name = "",
                    labels = c("Present","Missing")) +
    theme_minimal() +
    theme(axis.text.x  = element_text(angle=90, vjust=0.5)) +
    labs(x = "Variables in Dataset",
         y = "Rows / observations")+
    yikai_themes+
    yikai_labels+
    theme(panel.grid.minor = element_blank())+
    theme(panel.grid.major = element_blank())+
    labs(title = "Missing values across the dataset")

grid::grid.raster(logo, x = 0.79, y = 0.91, just = c('left', 'bottom'), width = unit(1.5, 'inches'))
  
```


]]


---
class: bg-main1, center, middle

# Part 2: Modeling and interpretation
---

```{r child='coeff_plot.Rmd', warning=F, message=F, cache= T}
```


---

```{r child='part2_modeling.Rmd', warning=F, message=F, cache = T}
```

---

```{r child='SHAP_interaction-plot2.Rmd', warning=F, message=F}
```

---

```{r child='SHAP_force_plot.Rmd', warning=F, message=F}
```

---

```{r child='references.Rmd', warning=F, message=F}
```




